ðŸš€ Local RAG Chatbot (FastAPI + Ollama + FAISS)
A lightweight Retrieval-Augmented Generation (RAG) chatbot that runs fully locally using:
âš¡ FastAPI (API layer)
ðŸ§  Ollama (LLM + embeddings)
ðŸ“¦ FAISS (vector database)
ðŸ“„ PDF/TXT document ingestion

Upload documents â†’ embed â†’ store in FAISS â†’ ask questions â†’ get answers grounded in your data.

**Features**
âœ… Upload PDF/TXT documents
âœ… Automatic chunking + embeddings
âœ… FAISS similarity search
âœ… Context-aware answers using LLM
âœ… Persistent storage (survives restart)
âœ… Lightweight & fast
âœ… Fully offline (Ollama local models)
âœ… Simple 2-endpoint API

**Requirements**
Python 3.10+
Ollama installed
pip install fastapi uvicorn faiss-cpu ollama numpy pypdf
ollama pull mistral
ollama pull nomic-embed-text
ollama serve
